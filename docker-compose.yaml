#fixme  Clone openIM Server project before using docker-compose,project addressï¼šhttps://github.com/OpenIMSDK/Open-IM-Server.git
version: "3"
services:
  mysql:
    image: mysql:5.7
    ports:
      - 13306:3306
      - 23306:33060
    container_name: mysql
    volumes:
      - ./components/mysql/data:/var/lib/mysql
      - /etc/localtime:/etc/localtime
    environment:
      MYSQL_ROOT_PASSWORD: openIM
    command: --log-bin=ff3fddca9b42-bin --binlog-format=mixed --server-id=1
    restart: always

  mongodb:
    image: mongo:4.0
    ports:
      - 37017:27017
    container_name: mongo
    command: --wiredTigerCacheSizeGB 1 --auth
    volumes:
      - ./components/mongodb/data/db:/data/db
      - ./components/mongodb/data/logs:/data/logs
      - ./components/mongodb/data/conf:/etc/mongo
      - ./script/mongo-init.sh:/docker-entrypoint-initdb.d/mongo-init.sh
    environment:
      - TZ=Asia/Shanghai
      # cache
      - wiredTigerCacheSizeGB=1
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=root
      - MONGO_INITDB_DATABASE=openIM
      - MONGO_USERNAME=openIM
      - MONGO_PASSWORD=openIM
    #
    restart: always

  redis:
    image: redis
    ports:
      - 16379:6379
    container_name: redis
    volumes:
      - ./components/redis/data:/data
      #redis config file
      - ./components/redis/config/redis.conf:/usr/local/redis/config/redis.conf
    environment:
      TZ: Asia/Shanghai
    restart: always
    sysctls:
      net.core.somaxconn: 1024
    command: redis-server --requirepass openIM --appendonly yes


  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - 2181:2181
    container_name: zookeeper
    volumes:
      - /etc/localtime:/etc/localtime
    environment:
      TZ: Asia/Shanghai
    restart: always
    networks:
        - kafka
  
  etcd:
    image: quay.io/coreos/etcd
    ports:
      - 2379:2379
      - 2380:2380
    container_name: etcd
    volumes:
      - /etc/timezone:/etc/timezone
      - /etc/localtime:/etc/localtime
    environment:
      ETCDCTL_API: 3
    restart: always
    command: /usr/local/bin/etcd --name etcd0 --data-dir /etcd-data --listen-client-urls http://0.0.0.0:2379 --advertise-client-urls http://0.0.0.0:2379 --listen-peer-urls http://0.0.0.0:2380 --initial-advertise-peer-urls http://0.0.0.0:2380 --initial-cluster etcd0=http://0.0.0.0:2380 --initial-cluster-token tkn --initial-cluster-state new

  minio:
    image: minio/minio
    ports:
      - 10005:9000
      - 9090:9090
    container_name: minio
    volumes:
      - /mnt/data:/data
      - /mnt/config:/root/.minio
    environment:
      MINIO_ROOT_USER: user12345
      MINIO_ROOT_PASSWORD: key12345
    restart: always
    command: minio server /data --console-address ':9090'


  open_im_server:
    # image: openim/open_im_server:v2.3.5
    build:
      context: ./
      dockerfile: deploy.Dockerfile
    container_name: open_im_server
    volumes:
      - ./logs:/Open-IM-Server/logs
      - ./config:/Open-IM-Server/config
      - ${DATA_DIR}/db/sdk:/Open-IM-Server/db/sdk
      - ./script:/Open-IM-Server/script
    restart: always
    network_mode: "host"
    logging:
      driver: json-file
      options:
        max-size: "1g"
        max-file: "2"
    env_file:
      - .env
    depends_on:
      - kafka
    #   - mysql
    #   - mongodb
    #   - redis
    #   - etcd
    #   - minio

  open_im_enterprise:
    image: openim/open_im_enterprise:v1.0.0
    container_name: open_im_enterprise
    volumes:
      - ./logs:/Open-IM-Enterprise/logs
      - ./docker-compose_cfg/config.yaml:/Open-IM-Enterprise/config/config.yaml
    restart: always
    depends_on:
      - mysql
      - mongodb
      - redis
      - etcd
      - minio
      - open_im_server
    network_mode: "host"
    logging:
      driver: json-file
      options:
        max-size: "1g"
        max-file: "2"
    environment:
      CONFIG_NAME: "/Open-IM-Enterprise"

  prometheus:
    image: prom/prometheus
    volumes:
      - ./docker-compose_cfg/prometheus-compose.yml:/etc/prometheus/prometheus.yml
      - ./docker-compose_cfg/rules:/etc/prometheus/rules
    container_name: prometheus
    #    ports:
    #    - 9091:9091
    depends_on:
      - open_im_server
    command: --web.listen-address=:9091 --config.file="/etc/prometheus/prometheus.yml"
    network_mode: "host"

  grafana:
    image: grafana/grafana
    volumes:
      # - ./grafana/dashboards/dashboard.json:/var/lib/grafana/dashboards/dashboard.json
      # - ./grafana/provisioning/dashboard.yaml:/etc/grafana/provisioning/dashboards/dashboard.yaml
      - ./docker-compose_cfg/datasource-compose.yaml:/etc/grafana/provisioning/datasources/datasource.yaml
      - ./docker-compose_cfg/grafana.ini:/etc/grafana/grafana.ini
      - ./docker-compose_cfg/node-exporter-full_rev1.json:/var/lib/grafana/dashboards/node-exporter-full_rev1.json
    container_name: grafana
    #    ports:
    #    - 10007:10007
    depends_on:
      - prometheus
    network_mode: "host"

  alertmanager:
    image: prom/alertmanager
    container_name: alertmanager
    restart: always
    ports:
      - "9093:9093"
    volumes:
      - ./docker-compose_cfg/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./docker-compose_cfg/alertmanager/data:/alertmanager/data
    network_mode: "host"

  node-exporter:
    image: quay.io/prometheus/node-exporter
    container_name: node-exporter
    restart: always
    ports:
      - "9100:9100"

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    hostname: kafka
    restart: unless-stopped
    ports:
      - 9092:9092
    volumes:
      - ./components/kafka/data:/kafka/kafka-logs-kafka
    environment:
      TZ: Asia/Shanghai
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: ""
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    depends_on:
      - zookeeper
    networks:
      - kafka

  kafka-webui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-webui
    restart: always
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS: kafka:9092
    depends_on:
      - kafka
    networks:
      - kafka

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.0
    container_name: elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - ./components/esdata/data:/usr/share/elasticsearch/data
    networks:
      - elk

  kibana:
    image: docker.elastic.co/kibana/kibana:7.12.0
    container_name: kibana
    restart: always
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    networks:
      - elk


networks:
  elk:
    driver: bridge
  kafka:
    driver: bridge
